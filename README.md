# Variational Autoencoder (VAE) 


## ğŸ“Œ Introduction
Variational Autoencoder (VAE)ëŠ” í™•ë¥ ì  ìƒì„± ëª¨ë¸ ì¤‘ í•˜ë‚˜ë¡œ, ë°ì´í„°ì˜ ì ì¬ í‘œí˜„(latent representation)ì„ í•™ìŠµí•˜ê³  ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ ì‹ ê²½ë§ì…ë‹ˆë‹¤.

## ğŸ— Theory & Concepts
1. **Autoencoder (AE) vs. Variational Autoencoder (VAE)**
   - AEëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ê³  ë³µì›í•˜ëŠ” ì—­í• ì„ í•˜ì§€ë§Œ, VAEëŠ” í™•ë¥ ì  ë¶„í¬ë¥¼ í•™ìŠµí•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŒ.
   - VAEëŠ” ì ì¬ ê³µê°„(latent space)ì— ì •ê·œ ë¶„í¬ë¥¼ ê°€ì •í•˜ê³ , KL Divergenceë¥¼ ì´ìš©í•´ ì´ë¥¼ í•™ìŠµí•¨.

2. **VAE Architecture**
   - Encoder: ì…ë ¥ ë°ì´í„°ë¥¼ ì ì¬ ë³€ìˆ˜ì˜ í™•ë¥  ë¶„í¬(í‰ê· , ë¶„ì‚°)ë¡œ ë³€í™˜
   - Latent Space: ìƒ˜í”Œë§ì„ í†µí•´ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„± ê°€ëŠ¥
   - Decoder: ìƒ˜í”Œë§ëœ ì ì¬ ë³€ìˆ˜ë¡œë¶€í„° ì›ë³¸ ë°ì´í„°ì™€ ìœ ì‚¬í•œ ë°ì´í„°ë¥¼ ìƒì„±

3. **Loss Function**
   - `Reconstruction Loss`: ì›ë³¸ ë°ì´í„°ì™€ ë³µì›ëœ ë°ì´í„° ê°„ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™”
   - `KL Divergence Loss`: ì ì¬ ë¶„í¬ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥´ë„ë¡ ìœ ë„



## ğŸ† Results
### âœ… MNIST ë°ì´í„°ì…‹ ê²°ê³¼ ì˜ˆì‹œ
![Reconstructed](https://github.com/ssoDTlab/VAE/blob/main/result.png)

## ğŸ”— References
- [Kingma & Welling, 2013 - Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)
- [TensorFlow VAE Tutorial](https://www.tensorflow.org/tutorials/generative/cvae)
- [PyTorch VAE Example](https://github.com/pytorch/examples/tree/main/vae)
